#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
View(data_w_title)
View(data_w_title)
####
data_w_title =  data_clean
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
corpus <- corpus(data_clean$Lyric)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
##################################
popular_words <- data_clean <-
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
View(dict_output)
View(dfmat_gov_lsd)
View(toks_gov_lsd)
toks=tokens(corpus365)
View(toks)
View(toks_gov_lsd)
toks_gov_lsd[["ANTI.1"]]
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
View(dfmat_gov_lsd)
print(dfmat_gov_lsd)
#########################
corpus365 = corpus(data_w_title, text_field = "Lyric")
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
View(toks_gov_lsd)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
View(dfmat_gov_lsd)
#########################
popular_words <- data_clean %>% group_by(Album) %>% count(word, Lyric, sort = TRUE)
library(dplyr) #data manipulation
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(quanteda)
library("quanteda.sentiment")
library(tidyr)
library("quanteda.textplots")
library("quanteda.textstats")
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
#########################
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Title)
docnames(corpus365) <- docid
corpus365
View(data)
corpus365
docid
#########################
corpus365 = corpus(data_clean, text_field = "Lyric")
corpus365
docid <- paste(data_clean$Title)
docid
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
View(dict_output)
sum <- dict_output[order(dict_output$afinn, decreasing = TRUE),]
ggplot(data = head(dict_output,15), aes(x = doc_id, y = afinn)) +
geom_point()
View(sum)
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
View(sum)
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) + ylim(0,250)
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) + ylim(0,250)+
geom_point()
ggplot(data = tail(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
#########################
corpus365 = corpus(data_clean, text_field = "Lyric")
corpus365
docid <- paste(data_clean$Title)
docid
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
sum <- dict_output[order(dict_output$afinn, decreasing = TRUE),]
ggplot(data = tail(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
View(toks_gov_lsd)
print(dfmat_gov_lsd)
summary(data_dictionary_afinn)
data_dictionary_AFINN
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_AFINN)
summary(data_dictionary_afinn)
data
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_AFINN)
summary(data_dictionary_afinn)
data
dfmat_gov_lsd <- dfm(toks_gov_lsd)
print(dfmat_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
sum <- dict_output[order(dict_output$afinn, decreasing = TRUE),]
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) + ylim(0,250)+
geom_point()
ggplot(data = tail(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
View(data_clean)
View(data)
data[284] <-NULL
library(dplyr) #data manipulation
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(quanteda)
library("quanteda.sentiment")
library(tidyr)
library("quanteda.textplots")
library("quanteda.textstats")
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data[284] <-NULL
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
corpus <- corpus(data_clean$Lyric)
#corpus <- corpus(unlist(data_clean))
corpus
dfm1 <- dfm(tokens(corpus))
topfeatures(dfm1)
dfm2 <- dfm_remove(dfm1, stopwords("en"))
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfm2 <- dfm_remove(dfm2, words_to_remove)
topfeatures(dfm2, n=100)
dfm_trim1<-dfm_trim(dfm2, min_termfreq = 10, verbose = FALSE)
set.seed(100)
textplot_wordcloud(dfm_trim1)
textplot_wordcloud(dfm_trim1, max_words = 75)
View(dfm_trim1)
################
library("quanteda.textstats")
features_dfm_inaug <- textstat_frequency(dfm2, n = 100)
features_dfm_inaug$feature <- with(features_dfm_inaug, reorder(feature, -frequency))
ggplot(features_dfm_inaug, aes(x = feature, y = frequency)) +
geom_point() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
##################
album = unique(data_clean$Album)
album
####
df_4 <- unlist(data_clean) %>% corpus() %>% tokens()
freq_weight <- textstat_frequency(dfm2,
groups = dfm2$Album)
ggplot(data = freq_weight, aes(x = nrow(freq_weight):1, y = frequency)) +
geom_point() +
facet_wrap(~ group, scales = "free") +
coord_flip() +
scale_x_continuous(breaks = nrow(freq_weight):1,
labels = freq_weight$feature) +
labs(x = NULL, y = "Relative frequency")
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
sum <- sum[order(sum$afinn, decreasing = TRUE),]
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
#########################
corpus365 = corpus(data_clean, text_field = "Lyric")
corpus365
docid <- paste(data_clean$Title)
docid
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_AFINN)
summary(data_dictionary_afinn)
data
dfmat_gov_lsd <- dfm(toks_gov_lsd)
print(dfmat_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
sum <- dict_output[order(dict_output$afinn, decreasing = TRUE),]
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) + ylim(0,250)+
geom_point()
View(features_dfm_inaug)
print(toks_gov_lsd)
##
dfmat_gov_lsd <- dfm(toks)
dfmat_gov_lsd <- dfm_lookup(dfmat_gov_lsd, dictionary = data_dictionary_AFINN)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
print(dfmat_gov_lsd)
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
corpus <- corpus(data_clean$Lyric)
dfm1 <- dfm(tokens(corpus))
topfeatures(dfm1)
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfm2 <- dfm1 %>% dfm_remove(stop_words("en")) %>% dfm_remove(words_to_remove)
topfeatures(dfm2, n=100)
dfm2 <- dfm1 %>% dfm_remove(stop_words("english")) %>% dfm_remove(words_to_remove)
dfm2 <- dfm1 %>% dfm_remove(stopwords("en")) %>% dfm_remove(words_to_remove)
topfeatures(dfm2, n=100)
##################
album = unique(data_clean$Album)
album
dfm3 <- unlist(data_clean$Album) %>% corpus() %>% tokens() %>%
tokens_remove(stopwords("english")) %>%
tokens_remove(words_to_remove) %>%
dfm() %>% dfm_group(groups = album) %>%
dfm_weight(scheme= "prop")
####
df_4 <- unlist(data_clean) %>% corpus() %>% tokens()
freq_weight <- textstat_frequency(dfm2,
groups = dfm2$Album)
corpus365 = corpus(data_clean, text_field = "Lyric")
print(dfmat_gov_lsd)
#########################
corpus365 = corpus(data_clean, text_field = "Lyric")
corpus365
docid <- paste(data_clean$Title)
docid
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_AFINN)
summary(data_dictionary_afinn)
data
dfmat_gov_lsd <- dfm(toks_gov_lsd)
print(dfmat_gov_lsd)
##############
corpus365 = corpus(data_clean, text_field = "Lyric")
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_AFINN)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
print(dfmat_gov_lsd)
data_dictionary_AFINN
##################################
data_filtered <- dfm2 %>% convert(to = "data.frame")
View(data_filtered)
View(data_filtered)
##################################
corpus365 = corpus(data_clean, text_field = "Lyric")
docid <- paste(data_clean$Album)
docnames(corpus365) <- docid
toks=tokens(corpus365)
dfmat_gov_lsd <- dfm(toks)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
View(dict_output)
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
View(dict_output)
sum <- data.frame(aggregate( ~ doc_id, dict_output, sum))
topfeatures(dfmat_gov_lsd, groups = Album)
plot(topfeatures(dfmat_gov_lsd, groups = Album))
top_words_by_album<-topfeatures(dfmat_gov_lsd, groups = Album)
View(top_words_by_album)
top_words_by_album[["A Girl Like Me"]]
View(top_words_by_album)
ggplot(top_words_by_album, aes(x = feature))

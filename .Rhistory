docnames
corpus365
library(dplyr) #data manipulation
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(quanteda)
library("quanteda.sentiment")
library(tidyr)
library("quanteda.textplots")
library("quanteda.textstats")
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
####
data_w_title =  data_clean
data_w_title$Title <- NULL
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
View(dfmat_gov_lsd)
dfmat_gov_lsd@docvars[["docname_"]]
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
tplot_sent <- ggplot(dict_output,
aes(x = reorder(name, sent_score),
y = sent_score,
colour = gov_opp)) +
geom_point(size = 3) +
coord_flip() +
labs(x = "Speaker", y = "Estimated sentiment")
tplot_sent
corpus365
plot(dict_output)
View(dict_output)
View(dict_output)
View(toks)
View(data_w_title)
View(dfmat_gov_lsd)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
plot(dict_output)
View(dfmat_gov_lsd)
View(dict_output)
View(dfmat_gov_lsd)
View(dfmat_gov_lsd)
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
View(dict_output)
ggplot2(dict_output)
library(ggplot2) #visualizations
ggplot2(dict_output)
ggplot(dict_output)
ggplot(dict_output,  aes(displ, hwy, colour = class)) +
geom_point()
ggplot(dict_output,  aes(displ, hwy, colour = doc_id)) +
geom_point()
View(dict_output)
tapply(dict_output$afinn, dict_output$doc_id, FUN=sum)
ggplot(cum)
cum = tapply(dict_output$afinn, dict_output$doc_id, FUN=sum)
ggplot(cum)
cum <- dict_output %>% group_by(docid) %>% sum(afinn)
cum <- dict_output %>% group_by(doc_id) %>% sum(afinn)
View(dict_output)
aggregate(afinn ~ doc_id, dict_output, sum)
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
View(sum)
plot(sum)
ggplot(sum)
View(sum)
ggplot(data = sum, aes(x = doc_id, y = afinn)) +
geom_point()
sum <- order(sum$afinn)
sum
sum <- sum[order(sum$afinn)]
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
sum <- sum[order(sum$afinn)]
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
#corpus <- corpus(data_clean$Lyric)
corpus <- corpus(unlist(data_clean))
corpus
dfm1 <- dfm(tokens(corpus))
topfeatures(dfm1)
dfm2 <- dfm_remove(dfm1, stopwords("en"))
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfm2 <- dfm_remove(dfm2, words_to_remove)
topfeatures(dfm2, n=100)
topfeatures(dfm1, n = 30,decreasing = FALSE)
dfm_trim1<-dfm_trim(dfm2, min_termfreq = 10, verbose = FALSE)
set.seed(100)
textplot_wordcloud(dfm_trim1)
textplot_wordcloud(dfm_trim1, max_words = 75)
################
library("quanteda.textstats")
features_dfm_inaug <- textstat_frequency(dfm2, n = 100)
features_dfm_inaug$feature <- with(features_dfm_inaug, reorder(feature, -frequency))
ggplot(features_dfm_inaug, aes(x = feature, y = frequency)) +
geom_point() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
##################
album = unique(data_clean$Album)
album
dfm3 <- unlist(data_clean$Album) %>% corpus() %>% tokens() %>%
tokens_remove(stopwords("english")) %>%
tokens_remove(words_to_remove) %>%
dfm() %>% dfm_group(groups = album) %>%
dfm_weight(scheme= "prop")
####
data_w_title =  data_clean
data_w_title$Title <- NULL
corpus2 = corpus(unlist(data_w_title))
corpus2 <- corpus_subset(corpus2, "Album" %in% c(unique(data_w_title$Album)))
corpus2
album = data_clean$Album
dfm3 <- corpus2 %>% tokens() %>%
tokens_remove(stopwords("english")) %>%
tokens_remove(words_to_remove) %>%
dfm() %>% dfm_group(groups = "Album") %>%
dfm_weight(scheme= "prop")
####
df_4 <- unlist(data_clean) %>% corpus() %>% tokens()
freq_weight <- textstat_frequency(dfm2,
groups = dfm2$Album)
ggplot(data = freq_weight, aes(x = nrow(freq_weight):1, y = frequency)) +
geom_point() +
facet_wrap(~ group, scales = "free") +
coord_flip() +
scale_x_continuous(breaks = nrow(freq_weight):1,
labels = freq_weight$feature) +
labs(x = NULL, y = "Relative frequency")
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
sum <- sum[order(sum$afinn)]
sum <- sum[order(afinn),]
View(sum)
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
#corpus <- corpus(data_clean$Lyric)
corpus <- corpus(unlist(data_clean))
corpus
dfm1 <- dfm(tokens(corpus))
topfeatures(dfm1)
dfm2 <- dfm_remove(dfm1, stopwords("en"))
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
dict_output$doc_id <- dfmat_gov_lsd@docvars[["Album"]]
View(dict_output)
sum <- data.frame(aggregate(afinn ~ doc_id, dict_output, sum))
View(sum)
sum <- sum %>% select(sort(afinn))
View(sum)
sum <- sum %>% select(sort(afinn))
sum_15 <- sum[order(sum$afinn, decreasing = TRUE),]
View(sum_15)
sum <- sum[order(sum$afinn, decreasing = TRUE),]
View(sum)
ggplot(data = head(sum,15), aes(x = doc_id, y = afinn)) +
geom_point()
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
#corpus <- corpus(data_clean$Lyric)
corpus <- corpus(unlist(data_clean))
corpus
dfm1 <- dfm(tokens(corpus))
topfeatures(dfm1)
dfm2 <- dfm_remove(dfm1, stopwords("en"))
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfm2 <- dfm_remove(dfm2, words_to_remove)
topfeatures(dfm2, n=100)
topfeatures(dfm1, n = 30,decreasing = FALSE)
dfm_trim1<-dfm_trim(dfm2, min_termfreq = 10, verbose = FALSE)
set.seed(100)
textplot_wordcloud(dfm_trim1)
################
library("quanteda.textstats")
features_dfm_inaug <- textstat_frequency(dfm2, n = 100)
features_dfm_inaug$feature <- with(features_dfm_inaug, reorder(feature, -frequency))
ggplot(features_dfm_inaug, aes(x = feature, y = frequency)) +
geom_point() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
View(data_clean)
View(features_dfm_inaug)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
View(data_clean)
##################################
popular_words <- data_clean <-
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
####
data_w_title =  data_clean
data_w_title$Title <- NULL
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
View(data_w_title)
View(data_w_title)
####
data_w_title =  data_clean
data <- read.csv("data/Rihanna.csv", na.strings = c("", "NA"), encoding = "UTF-8")
data$X <- NULL
data$Artist <- NULL
data$Album <- data$Album %>% replace_na("Single")
data$Lyric <- trimws(data$Lyric)
data_clean <- data %>% drop_na()
data_clean$Lyric <- trimws(data_clean$Lyric)
modify_contractions <- function(df){
df <- gsub("'re", " are", df)
df <- gsub("'m", " am", df)
df <- gsub("'d", " would", df)
df <- gsub("'ve", " have", df)
df <- gsub("'s", " is", df)
df <- gsub("can't", "can not", df)
df <- gsub("aren't","are not", df)
df <- gsub("'ll"," will", df)
df <- gsub("won't","will not", df)
df <- gsub("in'","ing", df)
df <- gsub("don't","do not", df)
df <- gsub("'cause","because", df)
df <- gsub("y'","you ", df)
df <- gsub("gonna","going to", df)
df <- gsub("c amon","come on", df)
df <- gsub("wanna","want to", df)
df <- gsub(" im "," i am ", df)
return(df)
}
data_clean$Lyric <- sapply(data_clean$Lyric, modify_contractions)
specialChars <- function(x) gsub("[^a-zA-Z0-9 ]", " ", x)
data_clean$Lyric <- sapply(data_clean$Lyric, specialChars)
############
corpus <- corpus(data_clean$Lyric)
####
data_w_title =  data_clean
data_w_title$Title <- NULL
##################################
popular_words <- data_clean <-
#####################
afinn <- read.delim(system.file("extdata/afinn/AFINN-111.txt",
package = "quanteda.sentiment"),
header = FALSE, col.names = c("word", "valence"))
head(afinn)
data_dictionary_afinn <- dictionary(list(afinn = afinn$word))
#valence(data_dictionary_afinn) <- list(afinn = afinn$valence)
#toks = tokens(corpus(data_clean$Lyric))
#tokssel <- tokens_select(toks, data_dictionary_afinn)
#tokssel
#valence(data_dictionary_afinn)$afinn[as.character(tokssel)]
corpus365 = corpus(data_w_title, text_field = "Lyric")
docid <- paste(data_w_title$Album)
docnames(corpus365) <- docid
corpus365
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
words_to_remove <- c("rihanna","ya", "t", "hey", "eh", "da", "oh","ya","pre","da","la","uh" )
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
dict_output <- convert(dfmat_gov_lsd, to = "data.frame")
View(dict_output)
View(dfmat_gov_lsd)
View(toks_gov_lsd)
toks=tokens(corpus365)
View(toks)
View(toks_gov_lsd)
toks_gov_lsd[["ANTI.1"]]
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
View(dfmat_gov_lsd)
print(dfmat_gov_lsd)
#########################
corpus365 = corpus(data_w_title, text_field = "Lyric")
toks=tokens(corpus365)
toks_gov_lsd <- tokens_lookup(toks, dictionary = data_dictionary_afinn)
View(toks_gov_lsd)
dfmat_gov_lsd <- dfm(toks_gov_lsd)
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, stopwords("en"))
dfmat_gov_lsd <- dfm_remove(dfmat_gov_lsd, words_to_remove)
View(dfmat_gov_lsd)
#########################
popular_words <- data_clean %>% group_by(Album) %>% count(word, Lyric, sort = TRUE)
